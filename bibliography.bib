@article{msca,
  title={Segnext: Rethinking convolutional attention design for semantic segmentation},
  author={Guo, Meng-Hao and Lu, Cheng-Ze and Hou, Qibin and Liu, Zhengning and Cheng, Ming-Ming and Hu, Shi-Min},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1140--1156},
  year={2022}
}

@inproceedings{eca,
  title={ECA-Net: Efficient channel attention for deep convolutional neural networks},
  author={Wang, Qilong and Wu, Banggu and Zhu, Pengfei and Li, Peihua and Zuo, Wangmeng and Hu, Qinghua},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11534--11542},
  year={2020}
}

@article{dmcount,
  title={Distribution matching for crowd counting},
  author={Wang, Boyu and Liu, Huidong and Samaras, Dimitris and Nguyen, Minh Hoai},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1595--1607},
  year={2020}
}

@inproceedings{pafpn,
  title={Ssd: Single shot multibox detector},
  author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part I 14},
  pages={21--37},
  year={2016},
  organization={Springer}
}

@inproceedings{fpn,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2117--2125},
  year={2017}
}

@inproceedings{weightedfpn,
  title={Weighted feature pyramid networks for object detection},
  author={Li, Xiaohan and Lai, Taotao and Wang, Shuaiyu and Chen, Quan and Yang, Changcai and Chen, Riqing and Lin, Jinxun and Zheng, Fu},
  booktitle={2019 IEEE Intl Conf on Parallel \& Distributed Processing with Applications, Big Data \& Cloud Computing, Sustainable Computing \& Communications, Social Computing \& Networking (ISPA/BDCloud/SocialCom/SustainCom)},
  pages={1500--1504},
  year={2019},
  organization={IEEE}
}

@article{fpanet,
  title={FPANet: feature pyramid attention network for crowd counting},
  author={Zhai, Wenzhe and Gao, Mingliang and Li, Qilei and Jeon, Gwanggil and Anisetti, Marco},
  journal={Applied Intelligence},
  pages={1--18},
  year={2023},
  publisher={Springer}
}

@article{atrouspyramid,
title = {Atrous convolutions spatial pyramid network for crowd counting and density estimation},
journal = {Neurocomputing},
volume = {350},
pages = {91-101},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.03.065},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219304059},
author = {Junjie Ma and Yaping Dai and Yap-Peng Tan},
keywords = {Crowd counting, Crowd density estimation, Multi-scale, Atrous convolutions},
abstract = {Scale variation because of perspective distortion is still a challenge for crowd analysis. To address this problem, an atrous convolutions spatial pyramid network (ACSPNet) is proposed to perform crowd counts and density maps for both sparse and congested scenarios. Atrous Convolutions sequenced with increasing atrous rates are utilized to exaggerate the receptive field and maintain the resolution of extracted features. Different rates of atrous convolution blocks in the pyramid are skip-connected to integrate multi-scale information and extent scale perception ability. Atrous Spatial Pyramid Pooling (ASPP) is employed to resample information at different scales and contain global context. We evaluate our ACSPNet on five challenging benchmark crowd counting datasets and our method achieves state-of-the-art mean absolute error (MAE) and mean squared error (MSE) performances.}
}

@inproceedings{scalepyramid,
  title={Scale pyramid network for crowd counting},
  author={Chen, Xinya and Bin, Yanrui and Sang, Nong and Gao, Changxin},
  booktitle={2019 IEEE winter conference on applications of computer vision (WACV)},
  pages={1941--1950},
  year={2019},
  organization={IEEE}
}

@article{spatiotemporaldilated,
  title={Spatiotemporal dilated convolution with uncertain matching for video-based crowd estimation},
  author={Ma, Yu-Jen and Shuai, Hong-Han and Cheng, Wen-Huang},
  journal={IEEE Transactions on Multimedia},
  volume={24},
  pages={261--273},
  year={2021},
  publisher={IEEE}
}

@inproceedings{adaptivedilated,
  title={Adaptive dilated network with self-correction supervision for counting},
  author={Bai, Shuai and He, Zhiqun and Qiao, Yu and Hu, Hanzhe and Wu, Wei and Yan, Junjie},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4594--4603},
  year={2020}
}

@inproceedings{dadnet,
  title={Dadnet: Dilated-attention-deformable convnet for crowd counting},
  author={Guo, Dan and Li, Kun and Zha, Zheng-Jun and Wang, Meng},
  booktitle={Proceedings of the 27th ACM international conference on multimedia},
  pages={1823--1832},
  year={2019}
}

@inproceedings{mcnn,
  title     = {Single-image crowd counting via multi-column convolutional neural network},
  author    = {Zhang, Yingying and Zhou, Desen and Chen, Siqin and Gao, Shenghua and Ma, Yi},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {589--597},
  year      = {2016}
}

@InProceedings{sanet,
  author = {Cao, Xinkun and Wang, Zhipeng and Zhao, Yanyun and Su, Fei},
  title = {Scale Aggregation Network for Accurate and Efficient Crowd Counting},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  month = {September},
  year = {2018}
}

@inproceedings{csrnet,
  title={Csrnet: Dilated convolutional neural networks for understanding the highly congested scenes},
  author={Li, Yuhong and Zhang, Xiaofan and Chen, Deming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1091--1100},
  year={2018}
}

@article{cffnet,
  title={CFFNet: Coordinated feature fusion network for crowd counting},
  author={Xia, Yinfeng and He, Yuqiang and Peng, Sifan and Yang, Qianqian and Yin, Baoqun},
  journal={Image and Vision Computing},
  volume={112},
  pages={104242},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{can,
  title={Context-aware crowd counting},
  author={Liu, Weizhe and Salzmann, Mathieu and Fua, Pascal},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5099--5108},
  year={2019}
}

@inproceedings{tednet,
  title={Crowd counting and density estimation by trellis encoder-decoder networks},
  author={Jiang, Xiaolong and Xiao, Zehao and Zhang, Baochang and Zhen, Xiantong and Cao, Xianbin and Doermann, David and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6133--6142},
  year={2019}
}

@article{sfanet,
  title={Dual path multi-scale fusion networks with attention for crowd counting},
  author={Zhu, Liang and Zhao, Zhijian and Lu, Chao and Lin, Yining and Peng, Yao and Yao, Tangren},
  journal={arXiv preprint arXiv:1902.01115},
  year={2019}
}

@article{dm,
  title={Distribution matching for crowd counting},
  author={Wang, Boyu and Liu, Huidong and Samaras, Dimitris and Nguyen, Minh Hoai},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1595--1607},
  year={2020}
}

@article{sganet,
  title={Crowd counting via segmentation guided attention networks and curriculum loss},
  author={Wang, Qian and Breckon, Toby P},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={23},
  number={9},
  pages={15233--15243},
  year={2022},
  publisher={IEEE}
}

@inproceedings{bayesian,
  title={Bayesian loss for crowd count estimation with point supervision},
  author={Ma, Zhiheng and Wei, Xing and Hong, Xiaopeng and Gong, Yihong},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6142--6151},
  year={2019}
}

@article{firstdensity,
  title={Learning to count objects in images},
  author={Lempitsky, Victor and Zisserman, Andrew},
  journal={Advances in neural information processing systems},
  volume={23},
  year={2010}
}

@article{shrimp_density_1,
  title={Shrimp egg counting with fully convolutional regression network and generative adversarial network},
  author={Zhang, Junjie and Yang, Guowei and Sun, Lihui and Zhou, Chao and Zhou, Xuefang and Li, Qian and Bi, Meihua and Guo, Jianlin},
  journal={Aquacultural Engineering},
  volume={94},
  pages={102175},
  year={2021},
  publisher={Elsevier}
}

@article{shrimp_density_2,
  title={A Deep-Learning-Based Fast Counting Methodology Using Density Estimation for Counting Shrimp Larvae},
  author={Hu, Wu-Chih and Chen, Liang-Bi and Hsieh, Meng-Heng and Ting, Yuan-Kai},
  journal={IEEE Sensors Journal},
  volume={23},
  number={1},
  pages={527--535},
  year={2022},
  publisher={IEEE}
}

@article{shrimp_density_3,
  title={Shrimpseed\_Net: Counting of Shrimp Seed Using Deep Learning on Smartphones for Aquaculture},
  author={Liu, Dan and Xu, BingQi and Cheng, Yuan and Chen, Hongyuan and Dou, Yu and Bi, Hai and Zhao, YunPeng},
  journal={IEEE Access},
  year={2023},
  publisher={IEEE}
}

@inproceedings{shrimp_seg1,
  title={Baby shrimp counting via automated image processing},
  author={Kesvarakul, Ramil and Chianrabutra, Chamaporn and Chianrabutra, Srisit},
  booktitle={Proceedings of the 9th International Conference on Machine Learning and Computing},
  pages={352--356},
  year={2017}
}

@inproceedings{shrimp_seg2,
  title={Vaname (Litopenaeus vannamei) shrimp fry counting based on image processing method},
  author={Solahudin, M and Slamet, W and Dwi, AS},
  booktitle={IOP Conference Series: Earth and Environmental Science},
  volume={147},
  number={1},
  pages={012014},
  year={2018},
  organization={IOP Publishing}
}

@article{shrimp_seg3,
  title={Image recognition method using Local Binary Pattern and the Random forest classifier to count post larvae shrimp},
  author={Kaewchote, Jirabhorn and Janyong, Sittichoke and Limprasert, Wasit},
  journal={Agriculture and Natural Resources},
  volume={52},
  number={4},
  pages={371--376},
  year={2018},
  publisher={Elsevier}
}

@article{shrimp_seg4,
  title={A combination of IoT and cloud application for automatic shrimp counting},
  author={Yeh, Chi-Tsai and Chen, Ming-Chih},
  journal={Microsystem Technologies},
  pages={1--8},
  year={2019},
  publisher={Springer}
}

@inproceedings{shrimp_seg5,
  title={Combination of canny edge detection and blob processing techniques for shrimp larvae counting},
  author={Awalludin, Ezmahamrul Afreen and Yaziz, MY Mat and Rahman, NR Abdul and Yussof, Wan Nural Jawahir Hj Wan and Hitam, Muhammad Suzuri and Arsad, TN T},
  booktitle={2019 IEEE International Conference on Signal and Image Processing Applications (ICSIPA)},
  pages={308--313},
  year={2019},
  organization={IEEE}
}

@article{shrimp_seg6,
  title={Portable Device for Ornamental Shrimp Counting Using Unsupervised Machine Learning.},
  author={Yeh, Chi-Tsai and Ling, Ming-Sheng},
  journal={Sensors \& Materials},
  volume={33},
  year={2021}
}





@inproceedings{shrimp_det2,
  title={Comparison of CNN-Based Design for Shrimp Seed Counting Machine},
  author={Nurmaida, Firnanda Pristiana and Dewantara, Bima Sena Bayu and Gunawan, Agus Indra and Mahendra, Alfany Riza and Prayanata, Julian Widya and Fasya, Zulfikar Davbi Mahendra and Trianto, Setyo Wahyu},
  booktitle={2023 International Electronics Symposium (IES)},
  pages={493--498},
  year={2023},
  organization={IEEE}
}

@inproceedings{det1,
  title={Marked point processes for crowd counting},
  author={Ge, Weina and Collins, Robert T},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2913--2920},
  year={2009},
  organization={IEEE}
}

@article{densitymapsurvey,
  title={A survey of crowd counting and density estimation based on convolutional neural network},
  author={Fan, Zizhu and Zhang, Hong and Zhang, Zheng and Lu, Guangming and Zhang, Yudong and Wang, Yaowei},
  journal={Neurocomputing},
  volume={472},
  pages={224--251},
  year={2022},
  publisher={Elsevier}
}

@Article{rcnn3,
AUTHOR = {Hong Khai, Teh and Abdullah, Siti Norul Huda Sheikh and Hasan, Mohammad Kamrul and Tarmizi, Ahmad},
TITLE = {Underwater Fish Detection and Counting Using Mask Regional Convolutional Neural Network},
JOURNAL = {Water},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {222},
URL = {https://www.mdpi.com/2073-4441/14/2/222},
ISSN = {2073-4441},
ABSTRACT = {Fish production has become a roadblock to the development of fish farming, and one of the issues encountered throughout the hatching process is the counting procedure. Previous research has mainly depended on the use of non-machine learning-based and machine learning-based counting methods and so was unable to provide precise results. In this work, we used a robotic eye camera to capture shrimp photos on a shrimp farm to train the model. The image data were classified into three categories based on the density of shrimps: low density, medium density, and high density. We used the parameter calibration strategy to discover the appropriate parameters and provided an improved Mask Regional Convolutional Neural Network (Mask R-CNN) model. As a result, the enhanced Mask R-CNN model can reach an accuracy rate of up to 97.48%.},
DOI = {10.3390/w14020222}
}

@inproceedings{shrimp_rcnn2,
  title={AI-assisted Automated Pipeline for Length Estimation, Visual Assessment of the Digestive Tract and Counting of Shrimp in Aquaculture Production.},
  author={Hashisho, Yousif and Dolereit, Tim and Segelken-Voigt, Alexandra and Bochert, Ralf and Vahl, Matthias},
  booktitle={VISIGRAPP (4: VISAPP)},
  pages={710--716},
  year={2021}
}

@inproceedings{shrimp_rcnn1,
  title={Two-phase instance segmentation for whiteleg shrimp larvae counting},
  author={Nguyen, Khai-Thinh and Nguyen, Chanh-Nghiem and Wang, Chien-Yao and Wang, Jia-Ching},
  booktitle={2020 IEEE International Conference on Consumer Electronics (ICCE)},
  pages={1--3},
  year={2020},
  organization={IEEE}
}

@article{yolo3,
  title={Bass detection model based on improved YOLOv5 in circulating water system},
  author={Xu, Longqin and Deng, Hao and Cao, Yingying and Liu, Wenjun and He, Guohuang and Fan, Wenting and Wei, Tangliang and Cao, Liang and Liu, Tonglai and Liu, Shuangyin},
  journal={PloS one},
  volume={18},
  number={3},
  pages={e0283671},
  year={2023},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{shrimp_yolo2,
title = {Automatic shrimp counting method using local images and lightweight YOLOv4},
journal = {Biosystems Engineering},
volume = {220},
pages = {39-54},
year = {2022},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2022.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S1537511022001234},
author = {Lu Zhang and Xinhui Zhou and Beibei Li and Hongxu Zhang and Qingling Duan},
keywords = {Shrimp counting, Computer vision, Deep learning, Local image, YOLOv4},
abstract = {Shrimp counting is a fundamental operation for biomass estimation in shrimp culture. It is also vital for achieving reasonable feeding and improving breeding efficiency. The application of computer vision technology in the counting of aquatic products is nondestructive and highly efficient. However, owing to the small size, transparent body, and complex background of shrimp in the actual culture environment, existing methods cannot ensure the lightweight of the model applied while satisfying the counting accuracy, and it is difficult to achieve accurate real-time shrimp counting. Therefore, an automatic shrimp counting method using local images and lightweight YOLOv4 (Light-YOLOv4) was proposed in this study. Multiple local shrimp images were randomly cropped from the original top-view images previously collected using image processing technologies to construct a counting dataset. Subsequently, a local shrimp counting model based on Light-YOLOv4 is constructed and trained using transfer learning. Based on the trained model, the number of shrimp in each local shrimp image was predicted. The number of shrimp in the original shrimp image was obtained through a merging process, and the number of shrimp in the culture area was determined using the frame average method. The method was tested on a real shrimp dataset, and the Light-YOLOv4 local shrimp counting model achieved a counting precision of 92.12%, recall of 94.21%, F1 value of 93.15%, and mean average precision of 93.16%. Compared with other counting models, the proposed method exhibits a better comprehensive performance in terms of the counting accuracy, model size, and detection speed. Furthermore, when shrimp were counted within the entire culture area, the results were consistent with the true values.}
}

@inproceedings{shrimp_yolo1,
  title={Automatic counting shrimp larvae based you only look once (YOLO)},
  author={Armalivia, Siska and Zainuddin, Zahir and Achmad, Andani and Wicaksono, Muh Arief},
  booktitle={2021 International Conference on Artificial Intelligence and Mechatronics Systems (AIMS)},
  pages={1--4},
  year={2021},
  organization={IEEE}
}

@incollection{loy2013crowd,
  title={Crowd counting and profiling: Methodology and evaluation},
  author={Loy, Chen Change and Chen, Ke and Gong, Shaogang and Xiang, Tao},
  booktitle={Modeling, Simulation and Visual Analysis of Crowds: A Multidisciplinary Perspective},
  pages={347--382},
  year={2013},
  publisher={Springer}
}

@inproceedings{bifpn,
  title={Efficientdet: Scalable and efficient object detection},
  author={Tan, Mingxing and Pang, Ruoming and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10781--10790},
  year={2020}
}

@article{vgg16,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}


@article{hu2022deep,
  title={A Deep-Learning-Based Fast Counting Methodology Using Density Estimation for Counting Shrimp Larvae},
  author={Hu, Wu-Chih and Chen, Liang-Bi and Hsieh, Meng-Heng and Ting, Yuan-Kai},
  journal={IEEE Sensors Journal},
  volume={23},
  number={1},
  pages={527--535},
  year={2022},
  publisher={IEEE}
}

@article{zhang2021shrimp,
  title={Shrimp egg counting with fully convolutional regression network and generative adversarial network},
  author={Zhang, Junjie and Yang, Guowei and Sun, Lihui and Zhou, Chao and Zhou, Xuefang and Li, Qian and Bi, Meihua and Guo, Jianlin},
  journal={Aquacultural Engineering},
  volume={94},
  pages={102175},
  year={2021},
  publisher={Elsevier}
}
